{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c1348d3-4c0e-450f-8faf-19503f61b7b2",
   "metadata": {},
   "source": [
    "# LlamaCloud Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57082f55-66e0-44e1-8072-2450405c21d1",
   "metadata": {},
   "source": [
    "## Step 0: Setup environment config for LlamaCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e83a35ec-8e6c-475c-827c-20f46c4a3c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "013c59e6-34b2-4685-b8c3-10b9e9afc3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LLAMA_CLOUD_API_KEY\"] = \"your-api-key\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9472b5e3-c203-410d-82a3-b19c7c0ed61b",
   "metadata": {},
   "source": [
    "## Step 1: Parse pdf with LlamaParse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f713c84-2774-45c8-b030-a572273724db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_parse import LlamaParse\n",
    "from llama_index.core import SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e83d26e5-05ea-4bac-a06c-987e06993f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = LlamaParse(\n",
    "    result_type=\"markdown\",  # \"markdown\" and \"text\" are available\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6414cbff-8b05-4599-bce6-5ce764600a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 1d2c0056-8a84-4036-8b5e-fb7081905a38\n"
     ]
    }
   ],
   "source": [
    "file_extractor = {\".pdf\": parser}\n",
    "reader = SimpleDirectoryReader(\n",
    "    input_files=['data_resnet/resnet.pdf'], \n",
    "    file_extractor=file_extractor\n",
    ")\n",
    "docs = reader.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25b8955-b6f7-43c2-8ba4-33a07fca0e2c",
   "metadata": {},
   "source": [
    "## Step 2: Build cloud index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba1896de-c850-44d2-8e79-cb75a04d669c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.indices.managed.llama_cloud import LlamaCloudIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d879e25-3ffc-4b90-9858-f9f3f6c83851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find your index at https://cloud.llamaindex.ai/project/82137f10-5033-48f4-9a01-7ffcda87cd81/deploy/968be726-0f47-428a-b839-1279e11c5df1\n"
     ]
    }
   ],
   "source": [
    "index = LlamaCloudIndex.from_documents(\n",
    "    name='resnet_0226',\n",
    "    documents=docs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8375bb94-3386-4a21-9f6e-a31c7ff55e5b",
   "metadata": {},
   "source": [
    "## Step 3: Use your retrieval endpoint "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b5cb21-8f98-490d-9468-cb30e12c3d83",
   "metadata": {},
   "source": [
    "If you have a reference to the index: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df510141-13be-4285-9fab-1906c56dc71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = index.as_retriever(rerank_top_n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63457127-5a86-4b78-81e9-848a07c37362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.7 ms, sys: 3.24 ms, total: 17.9 ms\n",
      "Wall time: 1.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nodes = retriever.retrieve('How are you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c3de876-fad7-41e4-b965-fb93b3909fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node ID: 3460eb38-8a3a-41f8-bc9d-763a1c90d9a6\n",
      "Text: (1e4)| | |0|0|1|2|3|4|5|6|  Figure 6. Training on CIFAR-10.\n",
      "Dashed lines denote training error, and bold lines denote testing\n",
      "error. Left: plain networks. The error of plain-110 is higher than 60%\n",
      "and not displayed. Middle: ResNets. Right: ResNets with 110 and 1202\n",
      "layers.  | |plain-20|plain-56|ResNet-20| |---|---|---|---| |std|\n",
      "|ResNet-56|ResNe...\n",
      "Score:  0.885\n",
      "\n",
      "Node ID: 79e524c8-2759-49f7-bbeb-a0f399e9dba2\n",
      "Text: 2). Identity shortcut connections add neither extra parameter\n",
      "nor computational complexity. The entire network can still be trained\n",
      "end-to-end by SGD with backpropagation, and can be easily implemented\n",
      "using common libraries (e.g., Caffe) without modifying the solvers.\n",
      "We present comprehensive experiments on ImageNet to show the\n",
      "degradation pro...\n",
      "Score:  0.868\n",
      "\n",
      "Node ID: 708ee92e-7047-4aba-93cd-1bb48883491e\n",
      "Text: Detection results on the PASCAL VOC 2007 test set. The baseline\n",
      "is the Faster R-CNN system. The system “baseline+++” include box\n",
      "refinement, context, and multi-scale testing in Table 9.  |system|net|\n",
      "data|mAP|areo|bike|bird|boat|bottle|bus|car|cat|chair|cow|table|dog|ho\n",
      "rse|mbike|person|plant|sheep|sofa|train|tv|\n",
      "|---|---|---|---|---|---|---|---|-...\n",
      "Score:  0.853\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for node in nodes:\n",
    "    print(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba5001d-fcdf-4888-8940-0e7db5372df4",
   "metadata": {},
   "source": [
    "Alternatively, you can directly create a retriever:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e4c651b-a1d0-40b0-91ce-a7a96fd701fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.indices.managed.llama_cloud import LlamaCloudRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2796361d-90cd-423c-9726-f638a7aefbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = LlamaCloudRetriever(\n",
    "    name='resnet',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "828c11dd-8b40-4262-a4c3-f0345b81a522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.5 ms, sys: 2.69 ms, total: 15.2 ms\n",
      "Wall time: 2.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nodes = retriever.retrieve('Who are you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58688348-fa6f-4daf-8d95-20604c6f5a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node ID: 07c406d7-97c2-4c81-b65f-0c9f31a5a263\n",
      "Text: Object detection mAP (%) on the PASCAL VOC 2007/2012 test sets\n",
      "using baseline Faster R-CNN. See also Table 10 and 11 for better\n",
      "results.  |3|layer index (sorted by magnitude)| |---|---| |std|2|\n",
      "|0|20|40|60|80|100|  Figure 7. Standard deviations (std) of layer\n",
      "responses on CIFAR-10. The responses are the outputs of each 3×3\n",
      "layer, after BN and be...\n",
      "Score:  0.917\n",
      "\n",
      "Node ID: 68e12522-2353-4ace-92fa-7759feb1325c\n",
      "Text: In addition, highway networks --- ### way networks have not\n",
      "demonstrated accuracy gains with ReLU [29] and the biases are omitted\n",
      "for simplifying no- extremely increased depth (e.g., over 100 layers).\n",
      "The operation F + x is performed by a shortcut connection and element-\n",
      "wise addition. We adopt the second nonlinearity after the addition\n",
      "(i.e., σ...\n",
      "Score:  0.916\n",
      "\n",
      "Node ID: 367323e5-617c-477f-9cf6-2b685e8196fb\n",
      "Text: ## Deep Residual Learning for Image Recognition  Kaiming He\n",
      "Xiangyu Zhang Shaoqing Ren Jian Sun Microsoft Research\n",
      "arXiv:1512.03385v1 [cs.CV] 10 Dec 2015 {kahe, v-xiangz, v-shren,\n",
      "jiansun@microsoft.com 20 20  ### Abstract  Deeper neural networks are\n",
      "more difficult to train. We present a residual learning framework to\n",
      "ease the training of network...\n",
      "Score:  0.907\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for node in nodes:\n",
    "    print(node)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
