{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c1348d3-4c0e-450f-8faf-19503f61b7b2",
   "metadata": {},
   "source": [
    "# LlamaCloud Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57082f55-66e0-44e1-8072-2450405c21d1",
   "metadata": {},
   "source": [
    "## Step 0: Setup environment config for LlamaCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e83a35ec-8e6c-475c-827c-20f46c4a3c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "013c59e6-34b2-4685-b8c3-10b9e9afc3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LLAMA_CLOUD_API_KEY\"] = \"llx-dtwGPSzMyBZ4Ui6aP63601meawVf9nrTBFU5nY3DCfpRMyHZ\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9472b5e3-c203-410d-82a3-b19c7c0ed61b",
   "metadata": {},
   "source": [
    "## Step 1: Parse pdf with LlamaParse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f713c84-2774-45c8-b030-a572273724db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_parse import LlamaParse\n",
    "from llama_index.core import SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e83d26e5-05ea-4bac-a06c-987e06993f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = LlamaParse(\n",
    "    result_type=\"markdown\",  # \"markdown\" and \"text\" are available\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6414cbff-8b05-4599-bce6-5ce764600a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 15527f95-b96c-4833-a01a-094507fa5e23\n"
     ]
    }
   ],
   "source": [
    "file_extractor = {\".pdf\": parser}\n",
    "reader = SimpleDirectoryReader(\n",
    "    input_files=['data_resnet/resnet.pdf'], \n",
    "    file_extractor=file_extractor\n",
    ")\n",
    "docs = reader.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25b8955-b6f7-43c2-8ba4-33a07fca0e2c",
   "metadata": {},
   "source": [
    "## Step 2: Build cloud index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba1896de-c850-44d2-8e79-cb75a04d669c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.indices.managed.llama_cloud import LlamaCloudIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d879e25-3ffc-4b90-9858-f9f3f6c83851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find your index at https://cloud.llamaindex.ai/project/82137f10-5033-48f4-9a01-7ffcda87cd81/deploy/4f1094cd-ac20-48be-a361-577d55a80990\n"
     ]
    }
   ],
   "source": [
    "index = LlamaCloudIndex.from_documents(\n",
    "    name='resnet',\n",
    "    documents=docs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8375bb94-3386-4a21-9f6e-a31c7ff55e5b",
   "metadata": {},
   "source": [
    "## Step 3: Use your retrieval endpoint "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b5cb21-8f98-490d-9468-cb30e12c3d83",
   "metadata": {},
   "source": [
    "If you have a reference to the index: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df510141-13be-4285-9fab-1906c56dc71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = index.as_retriever(rerank_top_n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63457127-5a86-4b78-81e9-848a07c37362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.9 ms, sys: 2.53 ms, total: 14.4 ms\n",
      "Wall time: 3.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nodes = retriever.retrieve('How are you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c3de876-fad7-41e4-b965-fb93b3909fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node ID: e24ecb70-f38a-46f9-a090-2f215271c14e\n",
      "Text: In ECCV, 2014.| --- ## A. Object Detection Baselines  In this\n",
      "section we introduce our detection method based on the baseline Faster\n",
      "R-CNN [32] system. The models are initialized by the ImageNet\n",
      "classification models, and then fine-tuned on the object detection\n",
      "data. We have experimented with ResNet-50/101 at the time of the\n",
      "ILSVRC & COCO 2015 d...\n",
      "Score:  0.873\n",
      "\n",
      "Node ID: 35b782a5-dcfd-40f2-9001-bb1421cacf2f\n",
      "Text: 2). Identity shortcut connections add neither extra parameter\n",
      "nor computational complexity. The entire network can still be trained\n",
      "end-to-end by SGD with backpropagation, and can be easily implemented\n",
      "using common libraries (e.g., Caffe) without modifying the solvers.\n",
      "We present comprehensive experiments on ImageNet to show the\n",
      "degradation pro...\n",
      "Score:  0.868\n",
      "\n",
      "Node ID: db16f701-0db5-4a0c-ad43-73e09f6ab994\n",
      "Text: Detection results on the PASCAL VOC 2007 test set. The baseline\n",
      "is the Faster R-CNN system. The system “baseline+++” include box\n",
      "refinement, context, and multi-scale testing in Table 9.  |system|net|\n",
      "data|mAP|areo|bike|bird|boat|bottle|bus|car|cat|chair|cow|table|dog|ho\n",
      "rse|mbike|person|plant|sheep|sofa|train|tv|\n",
      "|---|---|---|---|---|---|---|---|-...\n",
      "Score:  0.865\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for node in nodes:\n",
    "    print(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba5001d-fcdf-4888-8940-0e7db5372df4",
   "metadata": {},
   "source": [
    "Alternatively, you can directly create a retriever:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e4c651b-a1d0-40b0-91ce-a7a96fd701fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.indices.managed.llama_cloud import LlamaCloudRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2796361d-90cd-423c-9726-f638a7aefbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = LlamaCloudRetriever(\n",
    "    name='resnet',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "828c11dd-8b40-4262-a4c3-f0345b81a522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.5 ms, sys: 2.69 ms, total: 15.2 ms\n",
      "Wall time: 2.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nodes = retriever.retrieve('Who are you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58688348-fa6f-4daf-8d95-20604c6f5a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node ID: 07c406d7-97c2-4c81-b65f-0c9f31a5a263\n",
      "Text: Object detection mAP (%) on the PASCAL VOC 2007/2012 test sets\n",
      "using baseline Faster R-CNN. See also Table 10 and 11 for better\n",
      "results.  |3|layer index (sorted by magnitude)| |---|---| |std|2|\n",
      "|0|20|40|60|80|100|  Figure 7. Standard deviations (std) of layer\n",
      "responses on CIFAR-10. The responses are the outputs of each 3×3\n",
      "layer, after BN and be...\n",
      "Score:  0.917\n",
      "\n",
      "Node ID: 68e12522-2353-4ace-92fa-7759feb1325c\n",
      "Text: In addition, highway networks --- ### way networks have not\n",
      "demonstrated accuracy gains with ReLU [29] and the biases are omitted\n",
      "for simplifying no- extremely increased depth (e.g., over 100 layers).\n",
      "The operation F + x is performed by a shortcut connection and element-\n",
      "wise addition. We adopt the second nonlinearity after the addition\n",
      "(i.e., σ...\n",
      "Score:  0.916\n",
      "\n",
      "Node ID: 367323e5-617c-477f-9cf6-2b685e8196fb\n",
      "Text: ## Deep Residual Learning for Image Recognition  Kaiming He\n",
      "Xiangyu Zhang Shaoqing Ren Jian Sun Microsoft Research\n",
      "arXiv:1512.03385v1 [cs.CV] 10 Dec 2015 {kahe, v-xiangz, v-shren,\n",
      "jiansun@microsoft.com 20 20  ### Abstract  Deeper neural networks are\n",
      "more difficult to train. We present a residual learning framework to\n",
      "ease the training of network...\n",
      "Score:  0.907\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for node in nodes:\n",
    "    print(node)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
